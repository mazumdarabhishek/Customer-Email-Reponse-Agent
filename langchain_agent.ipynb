{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_groq import ChatGroq\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['TAVILY_API_KEY'] = os.getenv(\"TAVILY_API_KEY\")\n",
    "# os.environ['GOOGLE_API_KEY'] = os.getenv(\"GEMINI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are a Email catagorizer Agent. You are expert in understanding what a customer wants when they write an email and are\n",
    "able to categorize it in a desired way.<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Conduct a comprehensive analysis of the email provided and categorize into one of the following categories:\n",
    "        price_equiry - used when someone is asking for information about pricing \\\n",
    "        customer_complaint - used when someone is complaining about something \\\n",
    "        product_enquiry - used when someone is asking for information about a product feature, benefit or service but not about pricing \\\\\n",
    "        customer_feedback - used when someone is giving feedback about a product \\\n",
    "        off_topic -  when it doesnt relate to any other category \\\n",
    "\n",
    "Output a single catagory only from the types ('price_equiry', 'customer_complaint', 'product_enquiry', 'customer_feedback', 'off_topic') \\\n",
    "Output should be strictly a JSON with {{\"class\": \"<identified_catagory>\" }}\n",
    "for example: \n",
    "{{\"class\": \"price_enquiry\"}} \n",
    "\n",
    "EMAIL CONTENT: \\n\\n {initial_email} \\n\\n\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_PROMPT = PromptTemplate(\n",
    "    template=p1,\n",
    "    input_variables=['initial_email']\n",
    ")\n",
    "\n",
    "email_classifier_node = CLASSIFIER_PROMPT | model | JsonOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': 'customer_feedback'}\n"
     ]
    }
   ],
   "source": [
    "EMAIL = \"\"\"HI there, \\n\n",
    "I am emailing to say that I had a wonderful stay at your resort last week. \\n\n",
    "\n",
    "I really appreaciate what your staff did\n",
    "\n",
    "Thanks,\n",
    "Paul\n",
    "\"\"\"\n",
    "result = email_classifier_node.invoke({\"initial_email\": EMAIL})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 =\"\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are an expert at reading the initial email and routing web search or directly to a draft email. \\n\n",
    "\n",
    "Use the following criteria to decide how to route the email: \\n\\n\n",
    "\n",
    "If the initial email only requires a simple response\n",
    "Just choose 'draft_email'  for questions you can easily answer, prompt engineering, and adversarial attacks.\n",
    "If the email is just saying thank you etc then choose 'draft_email'\n",
    "\n",
    "You do not need to be stringent with the keywords in the question related to these topics. Otherwise, use research-info.\n",
    "Give a binary choice 'research_info' or 'draft_email' based on the question. Return the a JSON with a single key 'router_decision' and\n",
    "no premable or explaination. use both the initial email and the email category to make your decision\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "Email to route INITIAL_EMAIL : {initial_email} \\n\n",
    "EMAIL_CATEGORY: {email_category} \\n\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "\"\"\n",
    "ROUTER_PROMPT = PromptTemplate(\n",
    "    template=p2, input_variables=[\"initial_email\",\"email_category\"]\n",
    ")\n",
    "\n",
    "REASONING_ROUTER_NODE = ROUTER_PROMPT | model | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_decision': 'draft_email'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REASONING_ROUTER_NODE.invoke({\"initial_email\": EMAIL, \"email_category\":'customer_feedback'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Reccomendation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "import chromadb\n",
    "from langchain_core.documents import Document\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sephora_data = pd.read_csv(r\"C:\\Users\\abhis\\Downloads\\archive\\sephora_website_dataset.csv\")\n",
    "sephora_data.fillna(\"\", inplace=True)\n",
    "\n",
    "sephora_data[\"combined_context\"] = (\n",
    "    \"Brand : \" + sephora_data[\"brand\"] + \"\\n\" +\n",
    "    \"Category\" + sephora_data[\"category\"] + \"\\n\" + \n",
    "    \"name\" + sephora_data[\"name\"] + \"\\n\" +\n",
    "    \"details\" + sephora_data[\"details\"] + \"\\n\" +\n",
    "    \"Ingridients\" + sephora_data[\"ingredients\"] + \"\\n\" \n",
    ")\n",
    "\n",
    "docs = list()\n",
    "\n",
    "for i, row  in sephora_data.iterrows():\n",
    "\n",
    "    metadata = {\n",
    "        \"brand\": row['brand'],\n",
    "        \"category\": row['category'],\n",
    "        \"price\": row['price'],\n",
    "        \"rating\": row['rating'],\n",
    "        \"number_of_reviews\": row['number_of_reviews']\n",
    "    }\n",
    "\n",
    "    doc = Document(\n",
    "        page_content= row['combined_context'],\n",
    "        metadata= metadata\n",
    "    )\n",
    "\n",
    "    docs.append(doc)\n",
    "\n",
    "docs = docs[:300]\n",
    "\n",
    "persistent_client = chromadb.PersistentClient(path= \"sephora_store/chromadb/\")\n",
    "collection = persistent_client.get_or_create_collection(\"sephore_db\")\n",
    "\n",
    "embedding = OllamaEmbeddings(model=\"nomic-embed-text:latest\")\n",
    "\n",
    "# chroma = Chroma('sephora_db', embedding=embedding, client=persistent_client)\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    emb_vector = embedding.embed_query([doc.page_content])\n",
    "    collection.add(\n",
    "        documents=[doc.page_content],\n",
    "        metadata=[doc.metadata],\n",
    "        ids=[f\"id_{i}\"],\n",
    "        embeddings=[emb_vector]\n",
    "    )\n",
    "\n",
    "vector_store = Chroma(\n",
    "    client=persistent_client,\n",
    "    collection_name= \"sephora_db\",\n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name='brand',\n",
    "        description=\"The brand of the product. Examples include 'sephora collection', 'Fenty Beauty' etc\",\n",
    "        type=\"string\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name='category',\n",
    "        description=\"T  he category of the product such as 'skincare', 'makeup', 'hair' etc\",\n",
    "        type=\"string\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name='price',\n",
    "        description=\"The price of the product in USD\",\n",
    "        type=\"float\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name='rating',\n",
    "        description=\"The average user rating for a product from a sacle of 1 to 5\",\n",
    "        type=\"float\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name='number_of_reviews',\n",
    "        description=\"The total number of reviews given to a product\",\n",
    "        type=\"integer\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "document_content_description = \"COmbined  textual description of the product. Including ingredients and product details\"\n",
    "\n",
    "\n",
    "SelfQueryRetriever.from_llm(\n",
    "    model, \n",
    "    vector_store,\n",
    "    document_content_description,\n",
    "    metadata_field_info\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools import WriteFileTool\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def lookup_policy(query: str) -> str:\n",
    "    \"\"\"This tool is capable of finding relevant products from sephora, containing multiple\n",
    "    metadata filters that can be used to return product recommendations to the user.\n",
    "    \"\"\"\n",
    "    docs = retriever.invoke(query)\n",
    "    return \"\\n\\n\".join([doc.page_content + str(doc.metadata) for doc in docs])\n",
    "\n",
    "tool = WriteFileTool()\n",
    "tools = [tool, lookup_policy]\n",
    "\n",
    "llm = ChatGroq()\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "user_input = input(\"User: \")\n",
    "messages = {\"message\": [\"user\", user_input]}\n",
    "response = None\n",
    "for event in graph.stream(messages):\n",
    "    for value in event.values():\n",
    "        response = value[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
